{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f2d0ef0e307052a"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-27T19:01:55.498815Z",
     "start_time": "2025-12-27T19:01:43.415189Z"
    }
   },
   "source": [
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import random"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T19:01:55.515356Z",
     "start_time": "2025-12-27T19:01:55.508962Z"
    }
   },
   "cell_type": "code",
   "source": "print(random.uniform(1,6))",
   "id": "6d55a0988b289d70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7129553183846196\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dice Blackjack class (continuous)",
   "id": "c963fe20becee472"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T19:01:55.552321Z",
     "start_time": "2025-12-27T19:01:55.544932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DiceBlackjack:\n",
    "    DICE = 6\n",
    "    THRESHOLD = 11\n",
    "    HIT = 1\n",
    "    STAY = 0\n",
    "    LOST = -1\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        self.sum = 0\n",
    "        self.status = self.HIT\n",
    "\n",
    "\n",
    "    def roll_dice(self):\n",
    "        return random.uniform(1, 6) # was randint in the previous version\n",
    "\n",
    "\n",
    "    def make(self, move: int):\n",
    "        if move == self.STAY:\n",
    "            #print(\"Stay\")\n",
    "            self.status = self.STAY\n",
    "            return\n",
    "\n",
    "        else:\n",
    "            #print(\"Hit\")\n",
    "            self.sum += self.roll_dice()\n",
    "            if self.sum > self.THRESHOLD:\n",
    "                self.sum = 0\n",
    "                self.status = self.LOST\n",
    "            elif self.sum == self.THRESHOLD:\n",
    "                self.status = self.STAY\n",
    "        return\n",
    "\n",
    "\n",
    "    def clone(self):\n",
    "        c = DiceBlackjack()\n",
    "        c.sum = self.sum\n",
    "        c.status = self.status\n",
    "\n",
    "    def is_game_ended(self):\n",
    "        if self.status == self.HIT:\n",
    "            return False\n",
    "        return True\n"
   ],
   "id": "ab6a29dd818bd8a0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# CNN model creation\n",
    "### 1 input 1 output"
   ],
   "id": "83746c5e51c060c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T19:01:55.570592Z",
     "start_time": "2025-12-27T19:01:55.563744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_q_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(1,)),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ],
   "id": "c939277912d93cd7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model training\n",
    "### notice: normalization sum/11, training takes 20minutes"
   ],
   "id": "5cf0d448073c9341"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T19:18:54.959466Z",
     "start_time": "2025-12-27T19:01:55.595940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NUM_EPISODES = 5000\n",
    "EPSILON = 0.1\n",
    "\n",
    "model = create_q_model()\n",
    "\n",
    "print(\"Training started...\")\n",
    "\n",
    "for episode in range(NUM_EPISODES):\n",
    "    game = DiceBlackjack()\n",
    "    hit_states = [] #  HIT\n",
    "\n",
    "    while not game.is_game_ended():\n",
    "        if random.random() < EPSILON:\n",
    "            action = random.choice([game.HIT, game.STAY])\n",
    "        else:\n",
    "            state_input = np.array([[game.sum / 11]])\n",
    "            q_hit_value = model.predict(state_input, verbose=0)[0][0]\n",
    "            if q_hit_value > game.sum:\n",
    "                action = game.HIT\n",
    "            else: action = game.STAY\n",
    "\n",
    "        if action == game.HIT:\n",
    "            hit_states.append(game.sum)\n",
    "\n",
    "        game.make(action)\n",
    "\n",
    "    final_reward = game.sum\n",
    "\n",
    "    if len(hit_states) > 0:\n",
    "        X = np.array(hit_states) / 11.0\n",
    "        y = np.array([final_reward] * len(hit_states))\n",
    "        model.train_on_batch(X, y)  # can use model.fit BUT train_on_batch is faster for updating one specific game\n",
    "\n",
    "    if (episode + 1) % 500 == 0:\n",
    "        print(f\"Episode {episode + 1}/{NUM_EPISODES} completed.\")\n",
    "\n",
    "print(\"Training finished!\")"
   ],
   "id": "f4eccc975c3a8e77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "Episode 500/5000 completed.\n",
      "Episode 1000/5000 completed.\n",
      "Episode 1500/5000 completed.\n",
      "Episode 2000/5000 completed.\n",
      "Episode 2500/5000 completed.\n",
      "Episode 3000/5000 completed.\n",
      "Episode 3500/5000 completed.\n",
      "Episode 4000/5000 completed.\n",
      "Episode 4500/5000 completed.\n",
      "Episode 5000/5000 completed.\n",
      "Training finished!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluation\n",
   "id": "b753024d8a23d960"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T19:34:52.693332Z",
     "start_time": "2025-12-27T19:34:51.539490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EVAL_EPISODES = 100\n",
    "total_rewards = 0\n",
    "\n",
    "print(\"\\nStarting Evaluation (\", EVAL_EPISODES,\" episodes)...\")\n",
    "\n",
    "for i in range(EVAL_EPISODES):\n",
    "    game = DiceBlackjack()\n",
    "\n",
    "    while not game.is_game_ended():\n",
    "        state_input = np.array([[game.sum / 11.0]])\n",
    "        q_hit_value = model(state_input, training=False).numpy()[0][0]\n",
    "        if q_hit_value > game.sum:\n",
    "            action = game.HIT\n",
    "        else:\n",
    "            action = game.STAY\n",
    "        game.make(action)\n",
    "\n",
    "    total_rewards += game.sum\n",
    "\n",
    "avg_reward = total_rewards / EVAL_EPISODES\n",
    "print(f\"Average Reward over {EVAL_EPISODES} episodes: {avg_reward}\")"
   ],
   "id": "f9ba97f1a52d6d35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Evaluation ( 100  episodes)...\n",
      "Average Reward over 100 episodes: 8.366180211944638\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Pretty print made by llm",
   "id": "bc99f9d7efae1694"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T19:52:24.105139Z",
     "start_time": "2025-12-27T19:52:22.211232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n Learned Policy\")\n",
    "print(f\"{'Sum (S)':}    | {'Q(S, hit)':}    | {'Value(Stay)':}  | {'Decision'}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "test_sums = np.linspace(0, 11, 23)\n",
    "\n",
    "threshold_found = None\n",
    "\n",
    "for s in test_sums:\n",
    "    state_input = np.array([[s / 11.0]])\n",
    "    q_hit = model.predict(state_input, verbose=0)[0][0]\n",
    "\n",
    "    val_stay = s\n",
    "\n",
    "    if q_hit > val_stay:\n",
    "        decision = \"HIT\"\n",
    "    else:\n",
    "        decision = \"STAY\"\n",
    "        if threshold_found is None: # saw STAY for the first time\n",
    "            threshold_found = s\n",
    "\n",
    "    print(f\"{s:<10.1f} | {q_hit:<12.3f} | {val_stay:<12.1f} | {decision}\")\n",
    "\n",
    "print(\"-\" * 55)\n",
    "print(f\"\\nEstimated Threshold: The agent stops hitting around {threshold_found}\")"
   ],
   "id": "6b763e7b95c2c9b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Learned Policy\n",
      "Sum (S)    | Q(S, hit)    | Value(Stay)  | Decision\n",
      "-------------------------------------------------------\n",
      "0.0        | 7.354        | 0.0          | HIT\n",
      "0.5        | 7.415        | 0.5          | HIT\n",
      "1.0        | 7.476        | 1.0          | HIT\n",
      "1.5        | 7.536        | 1.5          | HIT\n",
      "2.0        | 7.558        | 2.0          | HIT\n",
      "2.5        | 7.563        | 2.5          | HIT\n",
      "3.0        | 7.558        | 3.0          | HIT\n",
      "3.5        | 7.535        | 3.5          | HIT\n",
      "4.0        | 7.500        | 4.0          | HIT\n",
      "4.5        | 7.464        | 4.5          | HIT\n",
      "5.0        | 7.393        | 5.0          | HIT\n",
      "5.5        | 7.297        | 5.5          | HIT\n",
      "6.0        | 7.202        | 6.0          | HIT\n",
      "6.5        | 7.106        | 6.5          | HIT\n",
      "7.0        | 7.011        | 7.0          | HIT\n",
      "7.5        | 6.915        | 7.5          | STAY\n",
      "8.0        | 6.820        | 8.0          | STAY\n",
      "8.5        | 6.724        | 8.5          | STAY\n",
      "9.0        | 6.629        | 9.0          | STAY\n",
      "9.5        | 6.533        | 9.5          | STAY\n",
      "10.0       | 6.438        | 10.0         | STAY\n",
      "10.5       | 6.342        | 10.5         | STAY\n",
      "11.0       | 6.247        | 11.0         | STAY\n",
      "-------------------------------------------------------\n",
      "\n",
      "Estimated Threshold: The agent stops hitting around 7.5\n"
     ]
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
